---
title: "Facial Recognition in the News"
date: 2023-09-19T09:04:30-04:00
tags: ["Facial Recognition Technology","News","ICT in the News", "FRT","MSG"]
author: "Nicholas Wadley"
show_reading_time: TRUE
---

# Introduction
Hey guys! It’s your boy Nick back at it with another blog post. For this piece, I will be analyzing the news article [“Facial recognition tech draws new criticism amid MSG controversy”](https://www.ny1.com/nyc/all-boroughs/news/2023/02/14/facial-recognition-tech-draws-new-criticism-amid-msg-controversy#:~:text='Automating%20the%20bias'&text=But%20details%20on%20how%20that,than%20middle%2Daged%20white%20men), written by Anna Sterling and its discussion of FRT. First, I will give an overall synopsis of the story. Next, I will look at the author’s language usage and how I believe it helped achieve her goal with the article. Finally, I’ll analyze some sources the author referenced and see if they are represented accurately. Hopefully, you guys don’t get bored by the end of this lol (no, seriously guys come on).

# Summary 
Guys, this article is a doozy, so I will try my best to give you a quick summary (with my limited word count). For starters, the owner of Madison Square Garden, James Dolan, uses facial recognition technology to prevent attorneys involved in litigation against him from entering the arena (ridiculous, I know). This brought up privacy and racial bias concerns from critics because people did not know what the arena was doing with people’s data, an issue paired with the alarming rates at which minorities are falsely scanned. Continuing the racism point, Sterling also discussed how New York law enforcement using FRTs would further “automate bias” because of how historically bad they are at scanning the faces of marginalized races, putting their safety at risk (especially Muslims because of 9/11). The author also mentioned concerns about how much the NYPD invests in FRT and how discrete those expenditures have become. However, a key political figure in the state proposed a bill to try and moderate the department’s use of facial recognition technology. Senator Holyman-Sigmal proposed the state should ban the use of the system altogether, effectively preventing the NYPD from using FRT to help solve a crime. (Sterling, 2023). Now that is how you assert yourself lol. I told you guys the summary would be a doozy! Despite that, we made it. Next, I will discuss what I believe the goal of the article was and the language used to achieve that goal. 

# Author's Language and How it Helps Achieve the Article's Goal

Based on my reading, I believe the language of Sterling’s article was mostly negative toward facial recognition technology. Furthermore, I am convinced it played a ubiquitous part in the goal of her piece, which I think was to inform people about the risks FRT can pose to the state of New York. For starters, the title of the article is a dead giveaway. That type of phrasing immediately sets a negative tone for the paper and paves the way for influencing a reader’s bias. A specific term for that is agenda setting, where the media forces our attention on topics (the negatives of FRT in this case) they think we believe are important. Furthermore, having an indicator like that immediately lets someone know that this piece probably won’t discuss the technology’s positives (which I will get to later), setting the stage for her to accomplish the article’s goal.
Towards the beginning of the article, moreover, Sterling mentions how privacy and accountability aren’t even the only flaws/criticisms of FRT, but racial discrepancies compound the technology’s weaknesses (Sterling, 2023). As you can see, the author continues with this theme of negativity regarding facial recognition technology. Also, that language paints a specific picture in the reader’s mind of any potential harm the system can have in NYC. Furthermore, that statement is a contribution towards the article's goal because it prefaces three major issues of FRT. Jeez Anna, why do you have to do FRTs like that?!? Simply uncalled for.                                                                                                                                                     Closer to the end of the article, Sterling talks about how the financials concerning FRTs had created disharmony between the New York City Council and the city’s police department. In 2020, the Council passed the P.O.S.T Act, which requires more clarity regarding citywide surveillance investments. However, the police department was not compliant with this policy. Furthermore, Sterling specifically threw in the fact that Alber Cahn (member of S.T.O.P., a civil liberty group) said that obtaining FRT expenditure records from the NYPD was an “uphill battle” (Sterling, 2023). That language can lead a reader to think that facial recognition technology is something that can create unnecessary conflict between two groups. Since it is such a useful tool, I am not surprised the police department kept their expenditures secret (especially if they are making illegal purchases). The negative language I highlighted further contributes to the article’s goal because it tells the reader how FRTs can cause shady practices (which would create major issues in the wrong hands). Maybe I’ll think twice before going back to visit because I do not want to be stalked by the police lol.

# Why the Lack of Positives?
Real quick, I would just love to shine a light on the fact that Sterling mentions ALMOST NO POSITIVES and includes little positive language toward FRTs in her article. Yes, there was a law passed to help keep track of expenditures regarding the technology, but that was made useless by the police’s refusal to comply. I believe it would have been great to include counterpoints to the technology’s flaws (accountability, racial discrepancies) and the police department’s shadiness that highlight how FRTs have assisted the NYPD with solving crimes successfully since 2011 (NYPD, n.d.). Sterling could also throw in a fact about how it can enhance overall security for any city in America, including New York (Mekinec, 2023). Ok, my soapbox is done. Next, will discuss the sources the author included and see if Sterling represented them accurately (let’s hope so).

# Analyzing the Author's Sources
To establish credibility in her article, Sterling utilized several trustworthy sources in the appropriate context. The first one she references is another Spectrum News article that discusses pending legal action being brought about by lawyers in Albany, New York. They too believe it is ridiculous to be kicked out of a game simply because they are involved in a litigation case against James Dolan, who is the owner of Madison Square Garden (Gross, 2019). Sterling hyperlinked that article in her piece to give the audience some context when she mentions how FRT use at the venue has sparked criticisms of the technology, and how it has been used to ban attorneys from entering the premises (Sterling, 2023). Based on that, I believe the author represented that source excellently. That other Spectrum News article combined with Sterling’s statements also ties back to the point I made earlier about how she wants to frame FRTs as a tool for creating friction between people. Unfortunately, it appears that is exactly what has happened here, especially since the attorneys were frustrated because they wanted to be part of the New York Knick family/atmosphere (Gross, 2019).
Three other sources Sterling referenced were studies that discussed how facial recognition is biased toward middle-aged Caucasian males, and how egregious the technology is at recognizing a minority’s face (specifically women in MIT’s findings) (Deng et al., n.d.; Hardesty, 2018; NIST, 2019). I believe the author represented those references in the correct context because they were all utilized in the “Automating the Bias” section of her article. This area discusses, you guessed, the racial prejudice in facial recognition technology. The author also noted that an interviewee of hers stated that this bias is a result of human training data, which is a bad sign for any investors (Sterling, 2023). Well, if they are not racist lol.

# Conclusion
Wow, guys, that was a lot. Hopefully, this blog post informed you all just how biased certain news outlets can be when it comes to facial recognition technology. I admit Sterling did use phenomenal sources to get her points across, but she barely acknowledged any positives of the situation with FRTs in New York, and just about the technology overall. I hope you guys enjoyed this piece, at least a tad bit lol.

# References
Beijing University of Posts and Telecommunications., Canon Information Technology (Beijing) Co., Ltd, Deng, W. (n.d.). *Racial Faces in the Wild: Reducing Racial Bias by Information Maximization Adaptation Network.*<https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Racial_Faces_in_the_Wild_Reducing_Racial_Bias_by_Information_ICCV_2019_paper.pdf>.

Gross, C. (2023, January 24). *Albany takes on attorney ban at Madison Square Garden.* Spectrum News NY1. <https://ny1.com/nyc/all-boroughs/politics/2023/01/25/albany-takes-on-attorney-ban-at-madison-square-garden> .

Hardesty, L. (2018, February 11). *Study finds gender and skin-type bias in commercial artificial-intelligence systems.* MIT News | Massachusetts Institute of Technology. <https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212>.

Mekinec, D. (2023, August 9). *Pros and cons of facial recognition.* Visage Technologies. <https://visagetechnologies.com/benefits-of-face-recognition/>. 

NIST. (2019, December 19). *NIST study evaluates effects of race, age, sex on face recognition software.* <https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software>.

NYPD. (n.d.). *NYPD questions and Answersfacial Recognition.* Facial Recognition - NYPD. <https://www.nyc.gov/site/nypd/about/about-nypd/equipment-tech/facial-recognition.page#:~:text=How%20is%20facial%20recognition%20used,%2C%20shootings%2C%20and%20other%20crimes>. 

Sterling, A. (2023, February 15). *Facial Recognition Tech draws new criticism amid msg controversy.* Facial recognition tech draws criticism amid MSG controversy. <https://ny1.com/nyc/all-boroughs/news/2023/02/14/facial-recognition-tech-draws-new-criticism-amid-msg-controversy#:~:text=%E2%80%99Automating%20the%20bias%E2%80%99&text=But%20details%20on%20how%20that,than%20middle%2Daged%20white%20men>. 

# Other Sources Referenced (Not mentioned in my blog)
George, J. (2021, January 21). *Staten Island da quietly purchased controversial facial recognition software.* Gothamist. <https://gothamist.com/news/staten-island-da-quietly-purchased-controversial-facial-recognition-software>

Katt, J., & Prashar, M. (2021, January 22). *Williams’ statement on the Staten Island district attorney’s use of Clearview AI facial recognition.* Office of the New York City Public Advocate. <https://www.pubadvocate.nyc.gov/press/williams-statement-staten-island-district-attorneys-use-clearview-ai-facial-recognition/> 

