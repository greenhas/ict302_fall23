---
title: "Matt Hill Background and Issue Introduction"
date: 2023-09-14T10:05:43-04:00
author: "Matt Hill"
draft: false
---
![an image of Matt Hill](https://i.imgur.com/r3deh0A.jpg)
# Work Experience
1.  Cherry Beckheart Accounting
2. [Twitch streaming](https://www.twitch.tv/snakejunior02)
3. Home Depot Electrical Assosiate
# Acheivments
1. Eagle Scout
2. North Oldham High School 2020 Graduate
4. University of Kentucky 2024 Information, Communication, and Technology

Matthew Hill
ICS 315
Professor Vallade
11/7/23
Deep-fake Litigation
AI technology has skyrocketed in popularity and availability in the last year in large part
due to the release of commercial AI services such as ChatGPT-3.5 or DAll-E. Artificial
Intelligence reads millions of images and articles to produce a desired outcome. The use of AI
just 5 years ago was a herculean task of assembling and training an AI off of a dataset. Now,
generative AI allows for anyone to create from massive datasets curated via online sources.
This can be used in nearly any way the designer intended which can result in a nearly 1 to 1
video of someone that never actually happened.These videos are referred to as “Deep Fakes''..
The first video to go viral of a deep fake was that of Obama in 2017 created by the University of
Washington (Bond, 2023). There are currently few cases to provide a legal precedent as to if
deepfakes can even be litigated. Many see these cases similarly to how they see other misuses
of a person's identity. The current precedents surrounding one's likeness are that of someone’s
right to publicity and misappropriation of one's image. Both of these topics hinge on being able
to prove the harm to one's image. This could take the form of scorned lovers or ex loyal fans
creating defamatory and untrue evidence of an event or action taking place. This type of issue
can be seen as the overwhelming majority of deep fakes are used to create pornography of
nonconsenting women.True evidence could also be downplayed or hidden behind a defense of
the video being deepfaked. These cases have increased in recent years as deep fake
technology has become virtually indistinguishable from normal videos. Two defendants that had
been alleged to have joined in the capitol riots on January 6th had claimed that video evidence
of them was deepfaked (Bond, 2023). In total, the lack of law regarding Deepfakes poses a
substantial legal threat through the creation of false information or obfuscation of evidence. 
The creation of lies and false information to harm a person's character has been an
issue since the founding of freedom of speech. Issues such as libel and slander have clear legal
avenues for recourse. Deep Fakes pose a unique threat to one's character as nearly 96% of all
deepfakes are to create pornographic material. In almost all of these cases, it is not the
creator's image that they are deepfaking but instead that of a celebrity, or coworker. There are
individuals that will sell these deep fakes for famous or semi-famous people to others for a
profit. Loss of one's identity is not the only harm that this use of deepfakes brings. In a High
School in New Jersey found students creating deep fake pornography of their underaged
classmates. The damage and harm to one's character and image is astronomical in cases such
as this. There is a possibility that one or all of these girls could be traumatized by this
experience from seeing these images created of them or even the knowledge that others have.
These girls could have difficulty with finding professional carriers in the future if AI pornography
is tied to their name through the internet. The gross misrepresentation of someone’s character
is compounded by a lack of legal recourse. A few states have taken action on this issue and
explicitly banned the creation of fake pornography (States Are Targeting Deepfake
Pornography—But Not in a Uniform Way, n.d.). This issue is not completely mitigated via a ban
as it can be difficult or impossible to find the individual that originally produced the faked image.
There are ways to erase metadata on videos and images which can create many layers before
the perpetrator is found. To ensure the safety of anyone on the internet's right to publicity there
must be actions taken to discern what is and is not a deep fake and negate their social power.
Deep Fakes in recent years have become so indistinguishable from other videos that
admitted legal evidence is being claimed as deepfaked as a defense in court (Bass et al.,
2023).. Legal battles over this issue are possible to hinder nearly every election or protest with
accusations of falsehood. Alongside this worry, is that of unknowingly lawyers submitting
falsified evidence which puts them at risk of being disbarred. Aside from disbarment, it is the
duty of the lawyer to submit and argue on the factual matters of the case. It could be considered 
massively irresponsible as a lawyer to use deepfakes as a tactic to prolong the trial (Bass et al.,
2023). One possible case of this Tesla was involved in a lawsuit regarding a fatal crash of a
self-driving car in which a video of Teslas Owner, Elon Musk, speaking very highly of the safety
of their cars. Musk’s lawyer argued that the video of him could have been deepfaked. This
ultimately led to Musk in a deposition speaking on the validity of the video in question (Bond,
2023). This defense offers a way for nearly anyone accused of a crime to posit that photo
evidence is deepfaked. This forces the other lawyers to prove that this could not have been a
deepfaked video. Authentication of videos without the use of metadata becomes very very
difficult. A jury may require an expert witness to explain what a deepfake is to have the
necessary context to make a decision. The ability for any lawyer in a court of law to make
possibly false claims that evidence is deep faked can drastically alter a verdict. In the event that
the evidence was not deepfaked, many hours of time in court could be wasted. Meanwhile, the
seeds of doubt could still remain that the evidence is inconclusive in the jurors mind. The legality
surrounding deep fakes allows for an almost “gray area” where the rules regarding evidence’s
validity are not well defined.
Deep fakes offer a look into the advancement of technology and the drastic impact it can
have on our legal system. This was much the same case for the invention of the internet and a
large reason for the laws that have today surrounding internet use. It takes action from
lawmakers to ensure that technology is not used to harm others or their image. One form of
action this could take is a mandatory watermark or signal to be hard coded into all AI and deep
fake creations (Mesa-Cucalon, 2021). This would allow for recognition at the source for whether
or not an image has been created using these practices.Tags also account for emergent deep
fake technology that is completely indistinguishable from the individual. This tag should also
include information regarding the creator as a way to hold individuals responsible for the things
they help to create. Recognition of the individual responsible for the creation of the deep fake
would dissuade many of the users creating deep fake pornography as it can be traced back to 
their name. This tag would similarly be seen by any deep faked document submitted to court as
evidence. A system such as this would allow for the litigation of deep fake cases to be similar to
that of copyright infringement of a person's likeness.This solution is hindered by the high cost
and slow implementation of this system.
There are other solutions which can be implemented while more robust measures are
created. Media literacy has the power to reduce much of the harm that can be done to
someone's image. If it were the case that nearly everyone that viewed a deep fake went through
the process of finding the original video or any corroborating information, they would find
nothing. This would allow for the deep fake to be much less effective and enables other users to
question the legitimacy of the individual posting the deep fake (Mesa-Cucalon, 2021). This
literacy may not curtail the users that are using deep fakes to create pornographic material.
However, understanding the material is deepfaked and giving users the knowledge to block or
report this individual. The users will also have the knowledge that this is a video used without
the permission of the individual they see in the video. This recognition of deep fake technology
and its similarity to real footage would assist all users in how they engage with online
information. As news shifts to become entirely online the use of deep fakes for political
motivations is likely. Media literacy will offer a way in which people can be much better informed
on true information. The main costs of this solution come from programs or lessons to teach
users how to analyze information. All users have the access to validate deep fakes, it is a matter
of utilizing the correct tools to do it.
Deep fakes and the lack of laws surrounding them provides a dangerous landscape for
users images and likenesses to be used without their consent. The misuse of this technology
has the power to significantly impact and hinder our current legal process. The very backbone of
our judicial system has glaring holes when it comes to exponentially growing technological
advancements. Actions must be taken in some form to curtail the flow and spread of 
misinformation. This issue only grows in scope and complexity month that it goes unaddressed
by law or social attention.
Bass, D. F., Penning, N., & on, S. A. (2023, July 25). The Legal Issues Surrounding
Deepfakes. https://www.honigman.com/the-matrix/the-legal-issues-surroundingdeepfakes
Bond, S. (2023, May 8). People are trying to claim real videos are deepfakes. The courts
are not amused. NPR. https://www.npr.org/2023/05/08/1174132413/people-are-tryingto-claim-real-videos-are-deepfakes-the-courts-are-not-amused
Delfino, R. (2023). The Deepfake Defense—Exploring the Limits of the Law and Ethical
Norms in Protecting Legal Proceedings from Lying Lawyers (SSRN Scholarly Paper
4355140). https://doi.org/10.2139/ssrn.4355140
Mesa-Cucalon, N. (2021, June 16). Deepfakes: Effective Solutions for Rapidly Emerging
Issues. Analytics Vidhya. https://medium.com/analytics-vidhya/deepfakes-effectivesolutions-for-rapidly-emerging-issues-8b1685feef56
States Are Targeting Deepfake Pornography—But Not in a Uniform Way. (n.d.). Legaltech
News. Retrieved November 7, 2023, from
https://www.law.com/legaltechnews/2023/08/10/states-are-targeting-deepfakepornography-but-not-in-a-uniform-way/